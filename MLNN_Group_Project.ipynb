{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik618aDHH3oe"
      },
      "outputs": [],
      "source": [
        "# To mount the colab notebook to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-erOgHU2IGcD"
      },
      "outputs": [],
      "source": [
        "# Module Imports\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yQ1zX6kH96O"
      },
      "outputs": [],
      "source": [
        "img = tf.keras.preprocessing.image.load_img('Group_Project_Data/Train/Real/img_0.png')\n",
        "img\n",
        "\n",
        "# Define the image directory path\n",
        "image_dir_train = \"Group_Project_Data/Train\"\n",
        "image_dir_valid = \"Group_Project_Data/Valid\"\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Define the image size\n",
        "img_size = (64, 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JabmL0wrICWv"
      },
      "outputs": [],
      "source": [
        "# Create the dataset using the image directory path\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=image_dir_train,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=img_size,\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    color_mode='grayscale',\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=image_dir_valid,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=img_size,\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    color_mode='grayscale',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCIrd5gPQcxG"
      },
      "outputs": [],
      "source": [
        "# Print the class names\n",
        "class_names = train_dataset.class_names\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ErTtBMrQmD-"
      },
      "outputs": [],
      "source": [
        "# Load the training data \n",
        "x_train = []\n",
        "y_train = []\n",
        "for images, labels in train_dataset:\n",
        "    x_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())\n",
        "\n",
        "x_train = np.concatenate(x_train, axis=0)\n",
        "y_train = np.concatenate(y_train, axis=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBwT6JgZQoAU"
      },
      "outputs": [],
      "source": [
        "# Load the validation data \n",
        "x_val = []\n",
        "y_val = []\n",
        "for images, labels in val_dataset:\n",
        "    x_val.append(images.numpy())\n",
        "    y_val.append(labels.numpy())\n",
        "\n",
        "x_val = np.concatenate(x_val, axis=0)\n",
        "y_val = np.concatenate(y_val, axis=0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kG8d2UCQpSc"
      },
      "outputs": [],
      "source": [
        "# Rescale the pixel values\n",
        "x_train = x_train/255.\n",
        "x_val = x_val/255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXm6HHXOYZNG"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture with L2 regularization\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1), kernel_regularizer=l2(0.001)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Print the summary of the model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_U3P0fjYZNH"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, batch_size =128, epochs=10)\n",
        "print(history.history.keys)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for Model Loss\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Training')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.legend(loc=0)\n",
        "plt.title('Model Loss')"
      ],
      "metadata": {
        "id": "2Zao1jhVYaiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for Model Accuracy\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='Training')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.legend(loc=0)\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WH8GCYMmZHpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model to predict \n",
        "y_pred = model.predict(x_val)\n",
        "y_pred_label = np.round(y_pred)\n",
        "\n",
        "# Plotting images with labels telling the truth and predicted values with some \n",
        "# testing images for each class\n",
        "f, ax = plt.subplots(5,5, figsize=(10, 12))\n",
        "ax = ax.flatten()\n",
        "\n",
        "# Looping the selected images from each class to show on the plot\n",
        "for i in range(25):\n",
        "    ax[i].imshow(x_val[i,:,:])\n",
        "    ax[i].set_title(f'Truth = {class_names[int(y_val[i])]}\\nPred = {class_names[int(y_pred_label[i])]}')\n",
        "    ax[i].set_xticks([])\n",
        "    ax[i].set_yticks([])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(len(x_val))"
      ],
      "metadata": {
        "id": "XLQ6DDIaZKg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model\n",
        "\n",
        "model.save('/content/Group_43_Model_Trained')"
      ],
      "metadata": {
        "id": "1vRxY5_cZNO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test saved model\n",
        "\n",
        "loaded_model = tf.keras.models.load_model('/content/Group_43_Model_Trained')\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "sz7jdw4UZZyn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}